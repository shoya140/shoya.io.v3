<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>shoya.io</title>
    <description></description>
    <link>http://shoya.io/</link>
    <atom:link href="http://shoya.io/feed.xml" rel="self" type="application/rss+xml" />
    <generator>Jekyll v2.5.3</generator>
    
      <item>
        <title>Sol-31</title>
        <description>&lt;p&gt;ドイツで生活を始めて1ヶ月になるのでこちらの暮らしについて振り返ってみようと思う。&lt;/p&gt;

&lt;p&gt;平日は7時くらいに目が覚めて9時に出社する。18時頃まで仕事して帰宅。家に帰ってからは日本でやっていた研究を論文にまとめたり趣味のプロジェクトを進めたり好きなことをして、24時くらいに眠りにつく。家の近くに大きな森があるので天気のいい日の朝や夕方はよく散歩に出かける。以前半年ほど住んでいたこともあって、街や食べ物には慣れているので日々の生活で心配なことは特にない。&lt;/p&gt;

&lt;p&gt;仕事について。予想通りだったのは皆短い時間で集中的に作業すること。17時を過ぎると研究所に誰もいなくなる。あと自分のやっていることや考えを積極的に主張する必要がある。働き始めてしばらく皆と打ち解けられずにいたんだけど、これまでやってきた研究内容をプレゼンした途端に「若いのにいろいろ面白いことやってるな！もっと見せてくれ！」と言われて関心もってもらえるようになった。Demo or Die.&lt;/p&gt;

&lt;p&gt;予想外だったのは言語の壁。普段の会話はドイツ語で交わされることの方が多いし、ミーティングでも参加者が増えるか1対1の会話になるとドイツ語になる傾向がある。早く聞き取れるようにならないとまずい。&lt;/p&gt;

&lt;p&gt;まだちょっと寒くてときどき雪が降る。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://dl.dropboxusercontent.com/u/12208857/img/life_in_germany03.JPG&quot; class=&quot;image-on-frame-small image-fade&quot; /&gt;&lt;/p&gt;
</description>
        <pubDate>Sun, 01 May 2016 00:00:00 +0900</pubDate>
        <link>http://shoya.io/blog/life-in-germany2/</link>
        <guid isPermaLink="true">http://shoya.io/blog/life-in-germany2/</guid>
        
        <category>Note</category>
        
        
        <category>diary</category>
        
      </item>
    
      <item>
        <title>AWSのGPUインスタンスでchainerとjupyter notebookを使う</title>
        <description>&lt;p&gt;AWSのアカウントを作成した状態から深層学習のための環境を作るまでの手順メモ&lt;/p&gt;

&lt;h2 id=&quot;section&quot;&gt;1. インスタンスの作成&lt;/h2&gt;

&lt;p&gt;インスタンス-&amp;gt;マーケットプレイス-&amp;gt;「nvidia」で検索。&lt;br /&gt;インスタンスタイプはg2.2xlargeまたはg2.8xlargeを選択。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://dl.dropboxusercontent.com/u/12208857/img/aws-chainer01.png&quot; class=&quot;image-on-frame-medium&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;cudnn&quot;&gt;2. cuDNNのインストール(任意)&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;https://developer.nvidia.com/cudnn&quot;&gt;NVIDIAのwebサイト&lt;/a&gt;でAccelerated Computing Developer Programに登録してダウンロード。登録が完了するまでに3日ほどかかる。ダウンロードしたものをインスタンス上で解凍して指定の位置に置く。&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;tar zxvf cudnn-6.5-linux-x64-v2.tgz
&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;sudo cp lib* /opt/nvidia/cuda/lib64/
&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;sudo cp cudnn.h /opt/nvidia/cuda/include/&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h2 id=&quot;chainerjupyter&quot;&gt;3. chainerとjupyterのセットアップ&lt;/h2&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;sudo &lt;span class=&quot;nv&quot;&gt;CUDA_PATH&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;/opt/nvidia/cuda pip install chainer
&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;sudo yum install gcc atlas-devel lapack-devel blas-devel libpng-devel freetype-devel
&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;sudo pip install scipy matplotlib pandas docopt scikit-learn jupyter&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;jupyter notebookを立ち上げてブラウザからアクセスできるようにする。&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;ipython
&lt;span class=&quot;c&quot;&gt;# 下記を実行して出力されたハッシュをコピー&lt;/span&gt;
from notebook.auth import passwd
passwd&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;mkdir ~/.jupyter
&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;vim ~/.jupyter/jupyter_notebook_config.py
&lt;span class=&quot;c&quot;&gt;# 下記の内容で保存&lt;/span&gt;
&lt;span class=&quot;nv&quot;&gt;c&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; get_config&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt;
c.NotebookApp.ip &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;*&amp;#39;&lt;/span&gt;
c.NotebookApp.password &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; u&lt;span class=&quot;s1&quot;&gt;&amp;#39;sha1:bcd259ccf...出力されたハッシュ&amp;#39;&lt;/span&gt;
c.NotebookApp.open_browser &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; False
c.NotebookApp.port &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; 任意のポート&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;セキュリティグループの設定で開けておく&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;jupyter notebook&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;SSL/HTTPSを使用する方法は&lt;a href=&quot;http://jupyter-notebook.readthedocs.io/en/latest/public_server.html&quot;&gt;こちら&lt;/a&gt;を参照。&lt;/p&gt;

&lt;h2 id=&quot;section-1&quot;&gt;3. イメージの作成とイメージからのインスタンス作成&lt;/h2&gt;

&lt;p&gt;イメージ(テンプレート)の作成はインスタンスのメニュー&amp;gt;イメージの作成を選択して行う。同時にスナップショットも作成される。ここまでの作業を終えたものをイメージにしておけば、以後はそのイメージから同様のインスタンスを作成することができる。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://dl.dropboxusercontent.com/u/12208857/img/aws-chainer02.png&quot; class=&quot;image-on-frame-medium&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://dl.dropboxusercontent.com/u/12208857/img/aws-chainer03.png&quot; class=&quot;image-on-frame-medium&quot; /&gt;&lt;/p&gt;
</description>
        <pubDate>Sun, 10 Apr 2016 00:00:00 +0900</pubDate>
        <link>http://shoya.io/blog/aws-chainer/</link>
        <guid isPermaLink="true">http://shoya.io/blog/aws-chainer/</guid>
        
        <category>Infrastructure</category>
        
        
        <category>tech</category>
        
      </item>
    
      <item>
        <title>大学院を修了してドイツで働くことになりました</title>
        <description>&lt;blockquote class=&quot;twitter-tweet&quot; data-lang=&quot;ja&quot;&gt;&lt;p lang=&quot;en&quot; dir=&quot;ltr&quot;&gt;It’s my pleasure to inform you that I have started working at DFKI, Kaiserslautern. &lt;a href=&quot;https://t.co/6Mol3GmIqG&quot;&gt;pic.twitter.com/6Mol3GmIqG&lt;/a&gt;&lt;/p&gt;&amp;mdash; Shoya Ishimaru (@shoya140) &lt;a href=&quot;https://twitter.com/shoya140/status/715863592902508544&quot;&gt;2016年4月1日&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async=&quot;&quot; src=&quot;//platform.twitter.com/widgets.js&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt;

&lt;p&gt;６年間通った大阪府立大学・大学院を卒業しました。大学前半の２年は白鷺祭、後半の２年はソフトウェア開発、大学院の２年は研究に没頭する毎日でした。
今日からはドイツ人工知能研究研究センター(DFKI)で研究者として働きながら博士号の取得を目指します。
しばらく日本を離れますが、なにかと用事で帰ってくる機会があると思います。皆さんとまたどこかでお会いできると嬉しいです。&lt;/p&gt;
</description>
        <pubDate>Fri, 01 Apr 2016 00:00:00 +0900</pubDate>
        <link>http://shoya.io/blog/DFKI2/</link>
        <guid isPermaLink="true">http://shoya.io/blog/DFKI2/</guid>
        
        <category>Note</category>
        
        
        <category>diary</category>
        
      </item>
    
      <item>
        <title>2015年振り返り</title>
        <description>&lt;p&gt;&lt;img src=&quot;https://dl.dropboxusercontent.com/u/12208857/img/looking_back_at_2015_01.JPG&quot; class=&quot;image-on-frame-small&quot; /&gt;&lt;/p&gt;

&lt;p&gt;新年あけましておめでとうございます。これまでの人生で最も忙しい日々が続いていて、振り返る間もなく2015年が終わっていた。忘れないうちに2015年のことを書いておこうと思う。&lt;/p&gt;

&lt;p&gt;春は&lt;strong&gt;韓国(国際会議)&lt;/strong&gt;、夏は&lt;strong&gt;アメリカ(インターンシップ)&lt;/strong&gt;・秋は&lt;strong&gt;フランス(留学)&lt;/strong&gt;といった感じで2014年に引き続き海外にでるチャンスに恵まれた一年だった。特に&lt;a href=&quot;/blog/1st_week_in_france/&quot;&gt;フランス留学&lt;/a&gt;では、1週目にディスカッションとテーマ決め、2週目に研究用ソフトウェア開発、3週目に被験者を集めてデータ記録、4週目に論文書いて提出(無事に採択された！)という、わずか1ヶ月で1つのプロジェクトを仕上げる濃い経験ができてとても良かった。様々な国の研究者との共同研究やディスカッションは研究を加速させるので、今後も積極的に海外にでたい。ちなみに冬は&lt;strong&gt;ドイツ(Dagstuhl Seminar)&lt;/strong&gt;に行く予定:)&lt;/p&gt;

&lt;p&gt;2016年もどうぞよろしくお願いします！！&lt;/p&gt;
</description>
        <pubDate>Sun, 03 Jan 2016 00:00:00 +0900</pubDate>
        <link>http://shoya.io/blog/looking-back-at-2015/</link>
        <guid isPermaLink="true">http://shoya.io/blog/looking-back-at-2015/</guid>
        
        <category>Note</category>
        
        
        <category>diary</category>
        
      </item>
    
      <item>
        <title>科学技術計算のためのPython開発環境(2015)</title>
        <description>&lt;h3 id=&quot;section&quot;&gt;機能&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;pyenv-virtualenvでバージョンと仮想環境を切り替えられる&lt;/li&gt;
  &lt;li&gt;OpenCV3.0をPythonから利用できる&lt;/li&gt;
  &lt;li&gt;Jupyter(iPython notebook)を起動できる&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;pyenv-virtualenv&quot;&gt;pyenv-virtualenvの導入&lt;/h3&gt;

&lt;p&gt;&lt;a href=&quot;http://brew.sh/&quot;&gt;Homebrew&lt;/a&gt;でインストールする。&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;brew install pyenv-virtualenv&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;.zshrc(.bashrc)に下記の設定を追記する。&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span class=&quot;nb&quot;&gt;export &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;PYENV_ROOT&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;${HOME}/.pyenv&amp;quot;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt; -d &lt;span class=&quot;s2&quot;&gt;&amp;quot;${PYENV_ROOT}&amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;then&lt;/span&gt;
    &lt;span class=&quot;nb&quot;&gt;eval&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;$(pyenv init -)&amp;quot;&lt;/span&gt;
    &lt;span class=&quot;nb&quot;&gt;eval&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;$(pyenv virtualenv-init -)&amp;quot;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;fi&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Pythonをインストール (例:3.5.10)&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;pyenv install 3.5.10
&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;pyenv global 3.5.10
&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;pyenv rehash&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h3 id=&quot;opencv&quot;&gt;OpenCVの導入&lt;/h3&gt;

&lt;p&gt;Homebrewでインストールする。&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;brew install opencv3 --with-python3&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;現在のPythonが見ているところにpathを通す。新しい仮想環境を作る度に下記のコマンドを実行する。&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span class=&quot;c&quot;&gt;# python2&lt;/span&gt;
&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;echo&lt;/span&gt; /usr/local/opt/opencv/lib/python2.7/site-packages &amp;gt; &lt;span class=&quot;k&quot;&gt;$(&lt;/span&gt;python -c &lt;span class=&quot;s2&quot;&gt;&amp;quot;from distutils.sysconfig import get_python_lib; print(get_python_lib())&amp;quot;&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;)&lt;/span&gt;/opencv.pth

&lt;span class=&quot;c&quot;&gt;# python3&lt;/span&gt;
&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;echo&lt;/span&gt; /usr/local/opt/opencv/lib/python3.5/site-packages &amp;gt; &lt;span class=&quot;k&quot;&gt;$(&lt;/span&gt;python -c &lt;span class=&quot;s2&quot;&gt;&amp;quot;from distutils.sysconfig import get_python_lib; print(get_python_lib())&amp;quot;&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;)&lt;/span&gt;/opencv.pth&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;numpyも一緒に入るけどpipで管理するものを使う&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;pip install numpy&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h3 id=&quot;jupyter&quot;&gt;Jupyterなど定番ライブラリの導入&lt;/h3&gt;

&lt;p&gt;pipでインストールする&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;pip install numpy scipy pandas scikit-learn matplotlib jupyter&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;virtualenvの上でmatplotlibを使うための設定&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;echo &lt;/span&gt;backend : TkAgg &amp;gt; ~/.matplotlib/matplotlibrc&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h3 id=&quot;virtualenv&quot;&gt;参考1 virtualenvの使い方&lt;/h3&gt;

&lt;p&gt;大体の場合はPythonのバージョン(2.7と3.5)を切り替えられるだけで十分だが、異なるバージョンのライブラリを使いたい時やテスト環境ではvirtualenvを使って仮想環境を用意する。&lt;/p&gt;

&lt;p&gt;virtualenvの作成 (例:tutorialディレクトリ以下では3.5.0から作った3.5.0-tutorialを使用する)&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;mkdir tutorial &lt;span class=&quot;o&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;cd &lt;/span&gt;tutorial
&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;pyenv virtualenv 3.5.0 3.5.0-tutorial
&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;pyenv &lt;span class=&quot;nb&quot;&gt;local &lt;/span&gt;3.5.0-tutorial&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;virtualenvの削除&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;pyenv uninstall 3.5.0-tutorial&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h3 id=&quot;osxlinux-windows&quot;&gt;参考2 OSX以外(Linux, Windows)での実行&lt;/h3&gt;

&lt;p&gt;scipyやOpenCVのセットアップで躓くことが多いのでminicondaを使っている。例えば下記のDockerfileからcontainerを作成してその上で実行する。(Python3系のcondaはOpenCVをサポートしていないので注意)&lt;/p&gt;

&lt;p&gt;&lt;cite&gt;&lt;a href=&quot;https://github.com/shoya140/docker-image-ml&quot;&gt;shoya140/docker-image-ml&lt;/a&gt;&lt;/cite&gt;&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-dockerfile&quot; data-lang=&quot;dockerfile&quot;&gt;&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; centos
&lt;span class=&quot;k&quot;&gt;MAINTAINER&lt;/span&gt; shoya140

&lt;span class=&quot;k&quot;&gt;RUN&lt;/span&gt; yum update -y
&lt;span class=&quot;k&quot;&gt;RUN&lt;/span&gt; yum install -y git curl gcc zlib-devel bzip2 bzip2-devel readline-devel sqlite sqlite-devel openssl openssl-devel

&lt;span class=&quot;k&quot;&gt;RUN&lt;/span&gt; git clone git://github.com/yyuu/pyenv.git .pyenv
&lt;span class=&quot;k&quot;&gt;ENV&lt;/span&gt; PYENV_ROOT &lt;span class=&quot;nv&quot;&gt;$HOME&lt;/span&gt;/.pyenv
&lt;span class=&quot;k&quot;&gt;ENV&lt;/span&gt; PATH &lt;span class=&quot;nv&quot;&gt;$PYENV_ROOT&lt;/span&gt;/shims:&lt;span class=&quot;nv&quot;&gt;$PYENV_ROOT&lt;/span&gt;/bin:&lt;span class=&quot;nv&quot;&gt;$PATH&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;RUN&lt;/span&gt; pyenv install miniconda-3.18.3
&lt;span class=&quot;k&quot;&gt;RUN&lt;/span&gt; pyenv global miniconda-3.18.3
&lt;span class=&quot;k&quot;&gt;RUN&lt;/span&gt; pyenv rehash

&lt;span class=&quot;k&quot;&gt;RUN&lt;/span&gt; conda install numpy scipy pandas scikit-learn
&lt;span class=&quot;k&quot;&gt;RUN&lt;/span&gt; conda install -c https://conda.binstar.org/menpo opencv&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

</description>
        <pubDate>Wed, 23 Dec 2015 00:00:00 +0900</pubDate>
        <link>http://shoya.io/blog/pyenv-virtualenv/</link>
        <guid isPermaLink="true">http://shoya.io/blog/pyenv-virtualenv/</guid>
        
        <category>Programming</category>
        
        
        <category>tech</category>
        
      </item>
    
      <item>
        <title>論文紹介『Orbits - Enabling Gaze Interaction in Smart Watches Using Moving Targets』</title>
        <description>&lt;p&gt;&lt;a href=&quot;http://qiita.com/advent-calendar/2015/hci&quot;&gt;ヒューマンコンピュータインタラクション論文紹介 Advent Calendar 2015&lt;/a&gt; 15日目の記事です。UbiComp2015で体験したデモの中から&lt;a href=&quot;http://dl.acm.org/citation.cfm?id=2800942&amp;amp;CFID=568698974&amp;amp;CFTOKEN=47187028&quot;&gt;Orbits: Enabling Gaze Interaction in Smart Watches Using Moving Targets&lt;/a&gt;を紹介します。投稿が遅くなりましてすみません…&lt;/p&gt;

&lt;div style=&quot;text-align:center;&quot;&gt;
&lt;iframe class=&quot;youtube-video&quot; src=&quot;https://www.youtube.com/embed/x6hbicxEFbg&quot; frameborder=&quot;0&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;&lt;/div&gt;

&lt;h3 id=&quot;section&quot;&gt;概要&lt;/h3&gt;
&lt;p&gt;円軌道上を動く点を見つめるといった視線入力を受け取るスマートウォッチ上のインターフェイス。画面上に位置・回転方向・半径・角速度の異なる軌道を配置することで、複数の軌道のなかからどれを見ているかを特定する。安価なアイトラッカで動作する点、キャリブレーションが不要な点、画面サイズに非依存な点が優れている。&lt;/p&gt;

&lt;h3 id=&quot;section-1&quot;&gt;有効性の検証&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;実験1:&lt;/strong&gt; 認識に多くのサンプルを使うと精度が向上するが入力に時間がかかる。注視の認識に最適なウインドウサイズを実験によって求めた。ターゲットを注視しているとき・ターゲットではなく文字盤を見ているとき・読書など他の行動をとっているときの視線を解析した結果、サイズは1秒間が良いと分かった。&lt;strong&gt;実験2:&lt;/strong&gt; ターゲットの数・角速度・半径を変化させた際の認識率の変化を調査した。ターゲット数&amp;gt;角速度&amp;gt;半径の順に大きく影響することが分かった(軌道半径による影響は極めて小さい)。&lt;/p&gt;

&lt;h3 id=&quot;section-2&quot;&gt;先行研究との比較&lt;/h3&gt;
&lt;p&gt;画面が小さく片手でしか操作できないスマートウォッチのインターフェイスに関する研究は広く行われているが、その多くは指による入力の領域を拡張するものである。また、画面上の動かない点を注視するタイプの視線入力は正確な位置推定のためにキャリブレーションを要する。&lt;/p&gt;

&lt;h3 id=&quot;section-3&quot;&gt;次に読むべき論文&lt;/h3&gt;
&lt;p&gt;&lt;a href=&quot;http://dl.acm.org/citation.cfm?id=2493477&quot;&gt;Pursuits: spontaneous interaction with displays based on smooth pursuit eye movement and moving targets.&lt;/a&gt; “軌道上を動く点を見つめる視線の認識”はこちらの論文のアイデアによるもの。&lt;/p&gt;

&lt;p&gt;デモではアイトラッカに&lt;a href=&quot;https://pupil-labs.com/pupil/&quot;&gt;pupil&lt;/a&gt;を使っていました。見ている対象は重要ではなく眼球運動のパターンが追えれば良いので、実は&lt;a href=&quot;https://jins-meme.com/ja/&quot;&gt;J!NS MEME&lt;/a&gt;でも同じようなことができるのではないかと思いました。&lt;/p&gt;
</description>
        <pubDate>Mon, 21 Dec 2015 00:00:00 +0900</pubDate>
        <link>http://shoya.io/blog/orbits/</link>
        <guid isPermaLink="true">http://shoya.io/blog/orbits/</guid>
        
        <category>Note</category>
        
        
        <category>diary</category>
        
      </item>
    
      <item>
        <title>Texpad LaTeX editorの紹介</title>
        <description>&lt;p&gt;&lt;a href=&quot;http://www.adventar.org/calendars/899&quot;&gt;できる Mac OS X Advent Calendar 2015&lt;/a&gt; 17日目の記事です。”Mac App Storeで3000円くらいするけど有益で十分金出す価値あるソフトの情報”ということで&lt;a href=&quot;https://itunes.apple.com/jp/app/texpad-latex-editor/id458866234&quot;&gt;Texpad&lt;/a&gt;について紹介します。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://dl.dropboxusercontent.com/u/12208857/img/texpad01.png&quot; class=&quot;image-on-frame-medium&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Texとは数式の処理に優れており論文やレポートの作成に使用されるマークアップ言語です。これまでTexを書くのにVim+linuxコマンドを使ったりTexShopに乗り換えたりSublime Text3+Build Systemを使ってみたりいろいろと試してきて、今はTexpadを使っています。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;blog/mac_tex/&quot;&gt;2014年におけるMac TeX環境 - shoya.io&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;/blog/sublime-latex/&quot;&gt;Sublime Text3でLaTeXをコンパイルする[Mac] - shoya.io&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;texpad&quot;&gt;TexPadの良いところ&lt;/h3&gt;

&lt;p&gt;エディタに必須な機能(シンタックスハイライト、オートコンプリート)が搭載されています。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://dl.dropboxusercontent.com/u/12208857/img/texpad02.png&quot; class=&quot;image-on-frame-medium&quot; /&gt;&lt;/p&gt;

&lt;p&gt;複数のタイプセットをサポートしていてPreferenceから切り替えることができます。(pdflatexとplatex-&amp;gt;dvipdfmxの違いを未だに理解していないので新しく論文を書くときは両方実行して通る方を使用してる)&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://dl.dropboxusercontent.com/u/12208857/img/texpad03.png&quot; class=&quot;image-on-frame-medium&quot; /&gt;&lt;/p&gt;

&lt;p&gt;そのほか、ショートカットキーでコンパイルできる点や.auxや.bblなどのコンパイル時に生成される中間物が./.texpadtmp/という不可視ディレクトリにまとめられる点も良いです。&lt;/p&gt;

&lt;h3 id=&quot;section&quot;&gt;導入方法&lt;/h3&gt;

&lt;p&gt;Texpadのコンパイル環境は別途用意する必要があります。&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;MacにTex環境を作る(&lt;a href=&quot;https://tug.org/mactex/&quot;&gt;MacTex&lt;/a&gt;がおすすめ)&lt;/li&gt;
  &lt;li&gt;AppStoreでTexpadを購入する&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;という手順で導入することができます。&lt;/p&gt;

&lt;p&gt;3400円(2015年12月現在)とやや高価ではありますがおすすめのアプリです。&lt;/p&gt;

&lt;div class=&quot;sticky-itslink&quot;&gt;&lt;a href=&quot;https://itunes.apple.com/jp/app/texpad-latex-editor/id458866234?mt=12&amp;amp;uo=4&quot; rel=&quot;nofollow&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;http://is3.mzstatic.com/image/thumb/Purple/v4/da/94/2a/da942ac4-54bc-63bc-764c-3be4c850f4db/source.icns/60x60bb.png&quot; style=&quot;float:left;margin:5px;&quot; alt=&quot;Texpad : LaTeX editor&quot; title=&quot;Texpad : LaTeX editor&quot; /&gt;&lt;/a&gt;&lt;div class=&quot;sticky-itslinktext&quot;&gt;&lt;a href=&quot;https://itunes.apple.com/jp/app/texpad-latex-editor/id458866234?mt=12&amp;amp;uo=4&quot; rel=&quot;nofollow&quot; target=&quot;_blank&quot;&gt;Texpad : LaTeX editor&lt;/a&gt;&lt;br /&gt;Valletta Ventures&lt;br /&gt;価格： 3,400円 &lt;a href=&quot;https://itunes.apple.com/jp/app/texpad-latex-editor/id458866234?mt=12&amp;amp;uo=4&quot; rel=&quot;nofollow&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;http://linkmaker.itunes.apple.com/htmlResources/assets//images/web/linkmaker/badge_macappstore-sm.png&quot; alt=&quot;iTunesで見る&quot; class=&quot;sticky-itslinkbadge&quot; /&gt;&lt;/a&gt;&lt;br /&gt;&lt;span style=&quot;font-size:xx-small;&quot;&gt;posted with &lt;a href=&quot;http://sticky.linclip.com/linkmaker/&quot; target=&quot;_blank&quot;&gt;sticky&lt;/a&gt; on 2015.12.24&lt;/span&gt;&lt;/div&gt;&lt;br style=&quot;clear:left;&quot; /&gt;&lt;/div&gt;
</description>
        <pubDate>Thu, 17 Dec 2015 00:00:00 +0900</pubDate>
        <link>http://shoya.io/blog/texpad/</link>
        <guid isPermaLink="true">http://shoya.io/blog/texpad/</guid>
        
        <category>Note</category>
        
        
        <category>diary</category>
        
      </item>
    
      <item>
        <title>JINS MEMEのセンサデータをグラフ表示・csv出力するアプリを作りました</title>
        <description>&lt;p&gt;&lt;img src=&quot;https://dl.dropboxusercontent.com/u/12208857/img/github_memelogger_ios_dev_01.png&quot; class=&quot;image-on-frame-small&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://qiita.com/advent-calendar/2015/jinsmeme&quot;&gt;JINS MEME Advent Calendar 2015&lt;/a&gt; 3日目の記事です。昨日の記事は@hatoneさんによる &lt;cite&gt;&lt;a href=&quot;http://hatone.hateblo.jp/entry/2015/12/01/162235&quot;&gt;JINE MEME iOSアプリ開発入門 -公式サンプルアプリを動かす-&lt;/a&gt;&lt;/cite&gt;でした。サンプルアプリが動いたら、次はセンサから得られるデータについてもっと詳しく見てみたいはず！今日はセンサデータをグラフ表示したり保存する方法について紹介します。記事の前半は作ったものの紹介で後半は実装の工夫です。&lt;/p&gt;

&lt;h3 id=&quot;section&quot;&gt;背景&lt;/h3&gt;

&lt;p&gt;センサを使って何か面白いものを作るならデータの観察は欠かせません。そこで、観察に便利な&lt;strong&gt;波形のモニタリング&lt;/strong&gt;と&lt;strong&gt;ラベル付データの記録&lt;/strong&gt;機能を持ったアプリを作って&lt;a href=&quot;https://github.com/shoya140/MEMELogger-iOS-developers&quot;&gt;githubで公開しました&lt;/a&gt;。READMEに従ってAPP_IDとAPP_SECRETを書いたKey.hを作成してから実行してみてください。&lt;/p&gt;

&lt;h3 id=&quot;section-1&quot;&gt;機能&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;アプリ上でセンサデータをグラフ表示できる&lt;/li&gt;
  &lt;li&gt;オフライン解析のためにデータを記録できる&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;section-2&quot;&gt;実装&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;グラフ描画&lt;/strong&gt; 直近のデータを配列として保持しておき、UIBezierPathで連結することで描画しています。上限下限や色などはStoryboard上で変えられるようにIBInspectableを設定しました。&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-swift&quot; data-lang=&quot;swift&quot;&gt;&lt;span class=&quot;p&quot;&gt;@&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;IBDesignable&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nl&quot;&gt;GraphView&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;UIView&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;@&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;IBInspectable&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;var&lt;/span&gt; &lt;span class=&quot;nl&quot;&gt;maximumValue&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Double&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;1000.0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;kr&quot;&gt;didSet&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;nb&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;setNeedsDisplay&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;データの記録&lt;/strong&gt; 開発者がデータの読み書きに使えるDocumentDirectory以下にテキストファイルを作成し、&lt;code&gt;memeRealTimeModeDataReceived(data: MEMERealTimeData!)&lt;/code&gt;が呼ばれる度にそのデータを追記しています。また、iTunesやiFunBoxを使ってデータを取り出せるように&lt;code&gt;プロジェクト名-info.plist&lt;/code&gt;にKey:&lt;code&gt;Application supports iTunes file sharing&lt;/code&gt; Value:&lt;code&gt;YES&lt;/code&gt;をセットしました。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;まばたきのアニメーション&lt;/strong&gt; &lt;a href=&quot;http://www.paintcodeapp.com/&quot;&gt;PaintCode&lt;/a&gt;を使ってPathの位置を変数で変えられる目の画像を作成しました。PaintCodeから出力されたStyleKitをimportして、目の開閉や虹彩の位置とともにdraw~を呼び出して描画しています。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://dl.dropboxusercontent.com/u/12208857/img/github_memelogger_ios_dev_03.png&quot; class=&quot;image-on-frame-medium&quot; /&gt;&lt;/p&gt;

&lt;p&gt;その他の細かい実装についてはリポジトリをご参照ください。&lt;/p&gt;

&lt;h3 id=&quot;section-3&quot;&gt;まとめ&lt;/h3&gt;

&lt;p&gt;JINS MEMEのデータを観察する際に役立つアプリを作って公開しました。ご活用ください。&lt;a href=&quot;http://qiita.com/advent-calendar/2015/jinsmeme&quot;&gt;JINS MEME Advent Calendar2015&lt;/a&gt; 明日の担当は古川さんとのことでとても楽しみです！&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/shoya140/MEMELogger-iOS-developers&quot;&gt;https://github.com/shoya140/MEMELogger-iOS-developers&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
        <pubDate>Thu, 03 Dec 2015 00:00:00 +0900</pubDate>
        <link>http://shoya.io/blog/meme-logger/</link>
        <guid isPermaLink="true">http://shoya.io/blog/meme-logger/</guid>
        
        <category>ReleaseNote</category>
        
        <category>Programming</category>
        
        
        <category>tech</category>
        
      </item>
    
      <item>
        <title>深層学習の自己符号化器を4行で記述できるライブラリを作りました</title>
        <description>&lt;p&gt;深層学習(DeepLeanring)の事前学習や特徴抽出に使われる積層自己符号化器(stacked auto-encoder)を簡単に記述するためのライブラリ(Chainerインターフェイス)を作りました。名前はzChainerです。&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://pypi.python.org/pypi/zChainer/&quot;&gt;zChainer - scikit-learn like interface and stacked autoencoder for chainer&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://dl.dropboxusercontent.com/u/12208857/img/zchainer01.png&quot; class=&quot;image-on-frame-medium&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;section&quot;&gt;なぜ作ったか&lt;/h3&gt;

&lt;p&gt;ニューラルネットワークを簡単に実装することができるライブラリとしてChainerが多くの方に利用されていますが、ほぼ同じ記述を繰り返し書く必要があったり、学習器の定義・評価の記述が煩雑になりがちであるという課題があります。そこでインターフェイスとなるライブラリがあれば便利だと思って開発しました。scikt-learn likeに使うためにscikit-chainerとxchainerを参考にさせていただきました。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;cite&gt;&lt;a href=&quot;http://qiita.com/lucidfrontier45/items/0568d0d9e2c125e72734&quot;&gt;chainerをscikit-learn likeに使えるようにした&lt;/a&gt;&lt;/cite&gt;&lt;/li&gt;
  &lt;li&gt;&lt;cite&gt;&lt;a href=&quot;http://blog.recruit-tech.co.jp/2015/09/02/xchainer-released/&quot;&gt;NNライブラリChainerをScikit-learn likeにガンガン拡張する&lt;/a&gt;&lt;/cite&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;作ってみると積層自己符号化器の実装も共通なコードが多いことに気付いたので、本ライブラリは積層自己符号化器を管理するところまでインターフェイスに含めてみました。後述のサンプルコードのとおり、少ない行数(整形のための改行を除けばわずか4行)で記述することができます。&lt;/p&gt;

&lt;h3 id=&quot;section-1&quot;&gt;機能&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Chainerをscikit-learnの学習器として使用できる&lt;/li&gt;
  &lt;li&gt;少ない行数でニューラルネットワークを記述できる&lt;/li&gt;
  &lt;li&gt;少ない行数で積層自己符号化器を記述できる&lt;/li&gt;
  &lt;li&gt;出力先を指定するだけでログやシリアライズされたモデルを出力できる&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;section-2&quot;&gt;インストール方法&lt;/h3&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;pip install zChainer&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h3 id=&quot;section-3&quot;&gt;サンプルコード&lt;/h3&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;np&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;chainer.functions&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;F&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;chainer.links&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;L&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;chainer&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ChainList&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;optimizers&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;zChainer&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;NNAutoEncoder&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;utility&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;..&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;astype&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;float32&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# encoderの定義&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# 例)ノード数784-200-100のネットワーク&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# 学習後に出力層(MNISTの場合はノード数10)をadd_linkする&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;encoder&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ChainList&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;L&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Linear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;784&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;200&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;L&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Linear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;200&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# decoderの定義&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# encoderとノード数を反対にしたLinkをChainする&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;decoder&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ChainList&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;L&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Linear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;200&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;784&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;L&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Linear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;200&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# NNAutoEncoderインスタンスの作成&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;ae&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;NNAutoEncoder&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;encoder&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;decoder&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;optimizers&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Adam&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;epoch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;log_path&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;quot;./ae_&amp;quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;utility&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;now&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;quot;_log.csv&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;export_path&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;quot;./ae_&amp;quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;utility&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;now&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;quot;.model&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# 学習&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;ae&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;forward関数にはdropoutありのreluを登録していますが、好みのforward関数をセットすることもできます。詳しくは&lt;a href=&quot;https://github.com/shoya140/zChainer&quot;&gt;github&lt;/a&gt;のexampleをご確認ください。&lt;/p&gt;

&lt;h3 id=&quot;section-4&quot;&gt;実装&lt;/h3&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;class NNAutoEncoder &lt;span class=&quot;o&quot;&gt;()&lt;/span&gt;:
    def __init__&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;self, encoder, decoder, optimizer,
        &lt;span class=&quot;nv&quot;&gt;epoch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;20, &lt;span class=&quot;nv&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;100, &lt;span class=&quot;nv&quot;&gt;log_path&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;&amp;quot;&lt;/span&gt;, &lt;span class=&quot;nv&quot;&gt;export_path&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;&amp;quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;:
        self.encoder &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; encoder
        self.decoder &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; decoder
        self.optimizer &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; optimizer
        self.epoch &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; epoch
        self.batch_size &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; batch_size
        self.log_path &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; log_path
        self.export_path &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; export_path
        self.autoencoded &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; ChainList&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt;

    def fit&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;self, x_train&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;:
        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; layer in range&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;0, len&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;self.encoder&lt;span class=&quot;o&quot;&gt;))&lt;/span&gt;:
            &lt;span class=&quot;c&quot;&gt;# Creating model&lt;/span&gt;
            self.model &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; ChainList&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;self.encoder&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;layer&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt;.copy&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt;, self.decoder&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;layer&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt;.copy&lt;span class=&quot;o&quot;&gt;())&lt;/span&gt;
            NNManager.forward &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; self.forward
            &lt;span class=&quot;nv&quot;&gt;nn&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; NNManager&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;self.model, self.optimizer, F.mean_squared_error,
                self.epoch, self.batch_size, self.log_path&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;

            &lt;span class=&quot;c&quot;&gt;# Training&lt;/span&gt;
            &lt;span class=&quot;nv&quot;&gt;x_data&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; self.encode&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;x_train, layer&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;.data
            nn.fit&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;x_data, x_data&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
            self.autoencoded.add_link&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;nn.model&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;0&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt;.copy&lt;span class=&quot;o&quot;&gt;())&lt;/span&gt;

        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; self.export_path !&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;&amp;quot;&lt;/span&gt;:
            pickle.dump&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;self.autoencoded, open&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;self.export_path, &lt;span class=&quot;s1&quot;&gt;&amp;#39;wb&amp;#39;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;, -1&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; self

    def predict&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;self, x_test&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;:
        raise Exception&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;Prediction for AutoEncoder is not implemented.&amp;quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;

    def encode&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;self, x, n&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;:
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;n&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; 0:
            &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; Variable&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;x&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt;:
            &lt;span class=&quot;nv&quot;&gt;h&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; self.encode&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;x, n-1&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; F.relu&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;self.autoencoded&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;n-1&lt;span class=&quot;o&quot;&gt;](&lt;/span&gt;h&lt;span class=&quot;o&quot;&gt;))&lt;/span&gt;

    def forward&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;self, x&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;:
        &lt;span class=&quot;nv&quot;&gt;h&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; F.dropout&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;F.relu&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;self.model&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;0&lt;span class=&quot;o&quot;&gt;](&lt;/span&gt;x&lt;span class=&quot;o&quot;&gt;)))&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; F.dropout&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;F.relu&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;self.model&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;1&lt;span class=&quot;o&quot;&gt;](&lt;/span&gt;h&lt;span class=&quot;o&quot;&gt;)))&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Chainer1.5のLink and Chainを使用しています。ネットワークの構造をChainではなくChainListとして管理することで各層に添字でアクセスできるようにして、学習が済んだものをself.autoencodedにコピーしています。学習済みモデル最先端の層からの出力はencoded関数を再帰的に呼ぶことで得ています。(層が深くなるにつれて遅くなるかも？時間ができれば改良したい)&lt;/p&gt;

&lt;h3 id=&quot;section-5&quot;&gt;まとめ&lt;/h3&gt;

&lt;p&gt;積層自己符号化器を含めたChainerのインターフェイスとなるライブラリを作成しました。時間の都合で十分検証ができていないので、不具合などあるかもしれません。おかしいところがあれば連絡いただけると嬉しいです。バージョン1.0になるまで使用は自己責任でお願いします。&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/shoya140/zChainer&quot;&gt;https://github.com/shoya140/zChainer&lt;/a&gt;&lt;/p&gt;
</description>
        <pubDate>Wed, 02 Dec 2015 00:00:00 +0900</pubDate>
        <link>http://shoya.io/blog/zchainer/</link>
        <guid isPermaLink="true">http://shoya.io/blog/zchainer/</guid>
        
        <category>ReleaseNote</category>
        
        <category>Programming</category>
        
        
        <category>tech</category>
        
      </item>
    
      <item>
        <title>大体いい感じの研究発表ができるKeynoteテンプレート「Zebra」を作った</title>
        <description>&lt;script async=&quot;&quot; class=&quot;speakerdeck-embed&quot; data-id=&quot;33dbc4b1166e45cca57400eeeaf0db4f&quot; data-ratio=&quot;1.33333333333333&quot; src=&quot;//speakerdeck.com/assets/embed.js&quot;&gt;&lt;/script&gt;

&lt;h3 id=&quot;section&quot;&gt;なぜ作ったか&lt;/h3&gt;

&lt;p&gt;僕の観測範囲では、研究発表のスライドというのは装飾が最小限で、白地に黒文字が読みやすくて良いとされています。その制約の中で見栄えの良いスライドを作るのはなかなか難しいので、大体いい感じになるKeynoteテンプレートを作りました。名前はZebraです。こちらからダウンロードすることができます。&lt;cite&gt;&lt;a href=&quot;https://github.com/shoya140/zebra&quot;&gt;Zebra — Keynote template for research presentations&lt;/a&gt;&lt;/cite&gt;&lt;/p&gt;

&lt;p&gt;テンプレート作成/公開にあたって参考にさせていただいたのは&lt;a href=&quot;http://www.sanographix.net/&quot;&gt;佐野章核&lt;/a&gt;さんの「Azusa」「Azusa Colors」で、勉強会やLTのスライドではいつもお世話になっています。
&lt;cite&gt;&lt;a href=&quot;http://memo.sanographix.net/post/82160791768&quot;&gt;大体いい感じになるKeynoteテンプレート「Azusa」作った - MEMOGRAPHIX&lt;/a&gt;&lt;/cite&gt; ただ研究発表のような堅い場所で使うにはややポップすぎる感じがするのと、透過でない図やグラフを貼る機会が多くて真っ白な背景が使いたいので、今回はそれに適したテンプレートを作成することにしました。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://dl.dropboxusercontent.com/u/12208857/img/zebra1.jpg&quot; class=&quot;image-on-frame-medium&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;section-1&quot;&gt;機能&lt;/h3&gt;

&lt;p&gt;title, outline, blank, mainの4種類のフォーマットと2種類のカラースキームで構成されています。mainのスライド上部には目立つが主張し過ぎない見出しを置いています。見出しの色は変えられるので好きな色を使ってください。スライドのメインカラーとリンクさせると綺麗です。スライドに使用する色は極力3色(背景・ベースカラー・メインカラー)に押さえて、課題-解決策の対比や強く伝えたいことにアクセントカラーを使うのが良いと思います。フォントはMac標準搭載のもののなかからAvenir Nextを選択しました。これも好みで選んでください。&lt;/p&gt;

&lt;h3 id=&quot;section-2&quot;&gt;まとめ&lt;/h3&gt;

&lt;p&gt;フォーマルだけど少しお洒落、大体いい感じの研究発表ができるKeynoteテンプレートを作って公開しました。ご活用ください。不具合などありましたらissue立てるか直接連絡いただけると嬉しいです。Zebra使って最高の卒論/修論発表にしようぜ！&lt;/p&gt;

&lt;p&gt;&lt;cite&gt;&lt;a href=&quot;https://github.com/shoya140/zebra&quot;&gt;Zebra — Keynote template for research presentations&lt;/a&gt;&lt;/cite&gt;&lt;/p&gt;
</description>
        <pubDate>Fri, 13 Nov 2015 00:00:00 +0900</pubDate>
        <link>http://shoya.io/blog/zebra/</link>
        <guid isPermaLink="true">http://shoya.io/blog/zebra/</guid>
        
        <category>ReleaseNote</category>
        
        <category>Design</category>
        
        
        <category>diary</category>
        
      </item>
    
  </channel>
</rss>
