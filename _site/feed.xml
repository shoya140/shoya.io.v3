<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>shoya.io</title>
    <description></description>
    <link>http://shoya.io/</link>
    <atom:link href="http://shoya.io/feed.xml" rel="self" type="application/rss+xml" />
    <generator>Jekyll v2.5.3</generator>
    
      <item>
        <title>2015年振り返り</title>
        <description>&lt;p&gt;&lt;img src=&quot;https://dl.dropboxusercontent.com/u/12208857/img/looking_back_at_2015_01.JPG&quot; class=&quot;image-on-frame-small&quot; /&gt;&lt;/p&gt;

&lt;p&gt;新年あけましておめでとうございます。これまでの人生で最も忙しい日々が続いていて、振り返る間もなく2015年が終わっていた。忘れないうちに2015年のことを書いておこうと思う。&lt;/p&gt;

&lt;p&gt;春は&lt;strong&gt;韓国(国際会議)&lt;/strong&gt;、夏は&lt;strong&gt;アメリカ(インターンシップ)&lt;/strong&gt;・秋は&lt;strong&gt;フランス(留学)&lt;/strong&gt;といった感じで2014年に引き続き海外にでるチャンスに恵まれた一年だった。特に&lt;a href=&quot;/blog/1st_week_in_france/&quot;&gt;フランス留学&lt;/a&gt;では、1週目にディスカッションとテーマ決め、2週目に研究用ソフトウェア開発、3週目に被験者を集めてデータ記録、4週目に論文書いて提出(無事に採択された！)という、わずか1ヶ月で1つのプロジェクトを仕上げる濃い経験ができてとても良かった。様々な国の研究者との共同研究やディスカッションは研究を加速させるので、今後も積極的に海外にでたい。ちなみに冬は&lt;strong&gt;ドイツ(Dagstuhl Seminar)&lt;/strong&gt;に行く予定:)&lt;/p&gt;

&lt;p&gt;2016年もどうぞよろしくお願いします！！&lt;/p&gt;
</description>
        <pubDate>Sun, 03 Jan 2016 00:00:00 +0900</pubDate>
        <link>http://shoya.io/blog/looking-back-at-2015/</link>
        <guid isPermaLink="true">http://shoya.io/blog/looking-back-at-2015/</guid>
        
        <category>Note</category>
        
        
        <category>diary</category>
        
      </item>
    
      <item>
        <title>科学技術計算のためのPython開発環境(2015)</title>
        <description>&lt;h3 id=&quot;section&quot;&gt;機能&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;pyenv-virtualenvでバージョンと仮想環境を切り替えられる&lt;/li&gt;
  &lt;li&gt;OpenCV3.0をPythonから利用できる&lt;/li&gt;
  &lt;li&gt;Jupyter(iPython notebook)を起動できる&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;pyenv-virtualenv&quot;&gt;pyenv-virtualenvの導入&lt;/h3&gt;

&lt;p&gt;&lt;a href=&quot;http://brew.sh/&quot;&gt;Homebrew&lt;/a&gt;でインストールする。&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;brew install pyenv-virtualenv&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;.zshrc(.bashrc)に下記の設定を追記する。&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span class=&quot;nb&quot;&gt;export &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;PYENV_ROOT&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;${HOME}/.pyenv&amp;quot;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt; -d &lt;span class=&quot;s2&quot;&gt;&amp;quot;${PYENV_ROOT}&amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;then&lt;/span&gt;
    &lt;span class=&quot;nb&quot;&gt;eval&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;$(pyenv init -)&amp;quot;&lt;/span&gt;
    &lt;span class=&quot;nb&quot;&gt;eval&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;$(pyenv virtualenv-init -)&amp;quot;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;fi&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Pythonをインストール (例:3.5.10)&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;pyenv install 3.5.10
&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;pyenv global 3.5.10
&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;pyenv rehash&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h3 id=&quot;opencv&quot;&gt;OpenCVの導入&lt;/h3&gt;

&lt;p&gt;Homebrewでインストールする。&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;brew install opencv3 --with-python3&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;現在のPythonが見ているところにpathを通す。新しい仮想環境を作る度に下記のコマンドを実行する。&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span class=&quot;c&quot;&gt;# python2&lt;/span&gt;
&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;echo&lt;/span&gt; /usr/local/opt/opencv/lib/python2.7/site-packages &amp;gt; &lt;span class=&quot;k&quot;&gt;$(&lt;/span&gt;python -c &lt;span class=&quot;s2&quot;&gt;&amp;quot;from distutils.sysconfig import get_python_lib; print(get_python_lib())&amp;quot;&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;)&lt;/span&gt;/opencv.pth

&lt;span class=&quot;c&quot;&gt;# python3&lt;/span&gt;
&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;echo&lt;/span&gt; /usr/local/opt/opencv/lib/python3.5/site-packages &amp;gt; &lt;span class=&quot;k&quot;&gt;$(&lt;/span&gt;python -c &lt;span class=&quot;s2&quot;&gt;&amp;quot;from distutils.sysconfig import get_python_lib; print(get_python_lib())&amp;quot;&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;)&lt;/span&gt;/opencv.pth&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;numpyも一緒に入るけどpipで管理するものを使う&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;pip install numpy&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h3 id=&quot;jupyter&quot;&gt;Jupyterなど定番ライブラリの導入&lt;/h3&gt;

&lt;p&gt;pipでインストールする&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;pip install numpy scipy pandas scikit-learn matplotlib jupyter&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;virtualenvの上でmatplotlibを使うための設定&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;echo &lt;/span&gt;backend : TkAgg &amp;gt; ~/.matplotlib/matplotlibrc&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h3 id=&quot;virtualenv&quot;&gt;参考1 virtualenvの使い方&lt;/h3&gt;

&lt;p&gt;大体の場合はPythonのバージョン(2.7と3.5)を切り替えられるだけで十分だが、異なるバージョンのライブラリを使いたい時やテスト環境ではvirtualenvを使って仮想環境を用意する。&lt;/p&gt;

&lt;p&gt;virtualenvの作成 (例:tutorialディレクトリ以下では3.5.0から作った3.5.0-tutorialを使用する)&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;mkdir tutorial &lt;span class=&quot;o&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;cd &lt;/span&gt;tutorial
&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;pyenv virtualenv 3.5.0 3.5.0-tutorial
&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;pyenv &lt;span class=&quot;nb&quot;&gt;local &lt;/span&gt;3.5.0-tutorial&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;virtualenvの削除&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;pyenv uninstall 3.5.0-tutorial&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h3 id=&quot;osxlinux-windows&quot;&gt;参考2 OSX以外(Linux, Windows)での実行&lt;/h3&gt;

&lt;p&gt;scipyやOpenCVのセットアップで躓くことが多いのでminicondaを使っている。例えば下記のDockerfileからcontainerを作成してその上で実行する。(Python3系のcondaはOpenCVをサポートしていないので注意)&lt;/p&gt;

&lt;p&gt;&lt;cite&gt;&lt;a href=&quot;https://github.com/shoya140/docker-image-ml&quot;&gt;shoya140/docker-image-ml&lt;/a&gt;&lt;/cite&gt;&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-dockerfile&quot; data-lang=&quot;dockerfile&quot;&gt;&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; centos
&lt;span class=&quot;k&quot;&gt;MAINTAINER&lt;/span&gt; shoya140

&lt;span class=&quot;k&quot;&gt;RUN&lt;/span&gt; yum update -y
&lt;span class=&quot;k&quot;&gt;RUN&lt;/span&gt; yum install -y git curl gcc zlib-devel bzip2 bzip2-devel readline-devel sqlite sqlite-devel openssl openssl-devel

&lt;span class=&quot;k&quot;&gt;RUN&lt;/span&gt; git clone git://github.com/yyuu/pyenv.git .pyenv
&lt;span class=&quot;k&quot;&gt;ENV&lt;/span&gt; PYENV_ROOT &lt;span class=&quot;nv&quot;&gt;$HOME&lt;/span&gt;/.pyenv
&lt;span class=&quot;k&quot;&gt;ENV&lt;/span&gt; PATH &lt;span class=&quot;nv&quot;&gt;$PYENV_ROOT&lt;/span&gt;/shims:&lt;span class=&quot;nv&quot;&gt;$PYENV_ROOT&lt;/span&gt;/bin:&lt;span class=&quot;nv&quot;&gt;$PATH&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;RUN&lt;/span&gt; pyenv install miniconda-3.18.3
&lt;span class=&quot;k&quot;&gt;RUN&lt;/span&gt; pyenv global miniconda-3.18.3
&lt;span class=&quot;k&quot;&gt;RUN&lt;/span&gt; pyenv rehash

&lt;span class=&quot;k&quot;&gt;RUN&lt;/span&gt; conda install numpy scipy pandas scikit-learn
&lt;span class=&quot;k&quot;&gt;RUN&lt;/span&gt; conda install -c https://conda.binstar.org/menpo opencv&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

</description>
        <pubDate>Wed, 23 Dec 2015 00:00:00 +0900</pubDate>
        <link>http://shoya.io/blog/pyenv-virtualenv/</link>
        <guid isPermaLink="true">http://shoya.io/blog/pyenv-virtualenv/</guid>
        
        <category>Programming</category>
        
        
        <category>tech</category>
        
      </item>
    
      <item>
        <title>論文紹介『Orbits - Enabling Gaze Interaction in Smart Watches Using Moving Targets』</title>
        <description>&lt;p&gt;&lt;a href=&quot;http://qiita.com/advent-calendar/2015/hci&quot;&gt;ヒューマンコンピュータインタラクション論文紹介 Advent Calendar 2015&lt;/a&gt; 15日目の記事です。UbiComp2015で体験したデモの中から&lt;a href=&quot;http://dl.acm.org/citation.cfm?id=2800942&amp;amp;CFID=568698974&amp;amp;CFTOKEN=47187028&quot;&gt;Orbits: Enabling Gaze Interaction in Smart Watches Using Moving Targets&lt;/a&gt;を紹介します。投稿が遅くなりましてすみません…&lt;/p&gt;

&lt;div style=&quot;text-align:center;&quot;&gt;
&lt;iframe class=&quot;youtube-video&quot; src=&quot;https://www.youtube.com/embed/x6hbicxEFbg&quot; frameborder=&quot;0&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;&lt;/div&gt;

&lt;h3 id=&quot;section&quot;&gt;概要&lt;/h3&gt;
&lt;p&gt;円軌道上を動く点を見つめるといった視線入力を受け取るスマートウォッチ上のインターフェイス。画面上に位置・回転方向・半径・角速度の異なる軌道を配置することで、複数の軌道のなかからどれを見ているかを特定する。安価なアイトラッカで動作する点、キャリブレーションが不要な点、画面サイズに非依存な点が優れている。&lt;/p&gt;

&lt;h3 id=&quot;section-1&quot;&gt;有効性の検証&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;実験1:&lt;/strong&gt; 認識に多くのサンプルを使うと精度が向上するが入力に時間がかかる。注視の認識に最適なウインドウサイズを実験によって求めた。ターゲットを注視しているとき・ターゲットではなく文字盤を見ているとき・読書など他の行動をとっているときの視線を解析した結果、サイズは1秒間が良いと分かった。&lt;strong&gt;実験2:&lt;/strong&gt; ターゲットの数・角速度・半径を変化させた際の認識率の変化を調査した。ターゲット数&amp;gt;角速度&amp;gt;半径の順に大きく影響することが分かった(軌道半径による影響は極めて小さい)。&lt;/p&gt;

&lt;h3 id=&quot;section-2&quot;&gt;先行研究との比較&lt;/h3&gt;
&lt;p&gt;画面が小さく片手でしか操作できないスマートウォッチのインターフェイスに関する研究は広く行われているが、その多くは指による入力の領域を拡張するものである。また、画面上の動かない点を注視するタイプの視線入力は正確な位置推定のためにキャリブレーションを要する。&lt;/p&gt;

&lt;h3 id=&quot;section-3&quot;&gt;次に読むべき論文&lt;/h3&gt;
&lt;p&gt;&lt;a href=&quot;http://dl.acm.org/citation.cfm?id=2493477&quot;&gt;Pursuits: spontaneous interaction with displays based on smooth pursuit eye movement and moving targets.&lt;/a&gt; “軌道上を動く点を見つめる視線の認識”はこちらの論文のアイデアによるもの。&lt;/p&gt;

&lt;p&gt;デモではアイトラッカに&lt;a href=&quot;https://pupil-labs.com/pupil/&quot;&gt;pupil&lt;/a&gt;を使っていました。見ている対象は重要ではなく眼球運動のパターンが追えれば良いので、実は&lt;a href=&quot;https://jins-meme.com/ja/&quot;&gt;J!NS MEME&lt;/a&gt;でも同じようなことができるのではないかと思いました。&lt;/p&gt;
</description>
        <pubDate>Mon, 21 Dec 2015 00:00:00 +0900</pubDate>
        <link>http://shoya.io/blog/orbits/</link>
        <guid isPermaLink="true">http://shoya.io/blog/orbits/</guid>
        
        <category>Note</category>
        
        
        <category>diary</category>
        
      </item>
    
      <item>
        <title>Texpad LaTeX editorの紹介</title>
        <description>&lt;p&gt;&lt;a href=&quot;http://www.adventar.org/calendars/899&quot;&gt;できる Mac OS X Advent Calendar 2015&lt;/a&gt; 17日目の記事です。”Mac App Storeで3000円くらいするけど有益で十分金出す価値あるソフトの情報”ということで&lt;a href=&quot;https://itunes.apple.com/jp/app/texpad-latex-editor/id458866234&quot;&gt;Texpad&lt;/a&gt;について紹介します。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://dl.dropboxusercontent.com/u/12208857/img/texpad01.png&quot; class=&quot;image-on-frame-medium&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Texとは数式の処理に優れており論文やレポートの作成に使用されるマークアップ言語です。これまでTexを書くのにVim+linuxコマンドを使ったりTexShopに乗り換えたりSublime Text3+Build Systemを使ってみたりいろいろと試してきて、今はTexpadを使っています。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;blog/mac_tex/&quot;&gt;2014年におけるMac TeX環境 - shoya.io&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;/blog/sublime-latex/&quot;&gt;Sublime Text3でLaTeXをコンパイルする[Mac] - shoya.io&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;texpad&quot;&gt;TexPadの良いところ&lt;/h3&gt;

&lt;p&gt;エディタに必須な機能(シンタックスハイライト、オートコンプリート)が搭載されています。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://dl.dropboxusercontent.com/u/12208857/img/texpad02.png&quot; class=&quot;image-on-frame-medium&quot; /&gt;&lt;/p&gt;

&lt;p&gt;複数のタイプセットをサポートしていてPreferenceから切り替えることができます。(pdflatexとplatex-&amp;gt;dvipdfmxの違いを未だに理解していないので新しく論文を書くときは両方実行して通る方を使用してる)&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://dl.dropboxusercontent.com/u/12208857/img/texpad03.png&quot; class=&quot;image-on-frame-medium&quot; /&gt;&lt;/p&gt;

&lt;p&gt;そのほか、ショートカットキーでコンパイルできる点や.auxや.bblなどのコンパイル時に生成される中間物が./.texpadtmp/という不可視ディレクトリにまとめられる点も良いです。&lt;/p&gt;

&lt;h3 id=&quot;section&quot;&gt;導入方法&lt;/h3&gt;

&lt;p&gt;Texpadのコンパイル環境は別途用意する必要があります。&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;MacにTex環境を作る(&lt;a href=&quot;https://tug.org/mactex/&quot;&gt;MacTex&lt;/a&gt;がおすすめ)&lt;/li&gt;
  &lt;li&gt;AppStoreでTexpadを購入する&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;という手順で導入することができます。&lt;/p&gt;

&lt;p&gt;3400円(2015年12月現在)とやや高価ではありますがおすすめのアプリです。&lt;/p&gt;

&lt;div class=&quot;sticky-itslink&quot;&gt;&lt;a href=&quot;https://itunes.apple.com/jp/app/texpad-latex-editor/id458866234?mt=12&amp;amp;uo=4&quot; rel=&quot;nofollow&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;http://is3.mzstatic.com/image/thumb/Purple/v4/da/94/2a/da942ac4-54bc-63bc-764c-3be4c850f4db/source.icns/60x60bb.png&quot; style=&quot;float:left;margin:5px;&quot; alt=&quot;Texpad : LaTeX editor&quot; title=&quot;Texpad : LaTeX editor&quot; /&gt;&lt;/a&gt;&lt;div class=&quot;sticky-itslinktext&quot;&gt;&lt;a href=&quot;https://itunes.apple.com/jp/app/texpad-latex-editor/id458866234?mt=12&amp;amp;uo=4&quot; rel=&quot;nofollow&quot; target=&quot;_blank&quot;&gt;Texpad : LaTeX editor&lt;/a&gt;&lt;br /&gt;Valletta Ventures&lt;br /&gt;価格： 3,400円 &lt;a href=&quot;https://itunes.apple.com/jp/app/texpad-latex-editor/id458866234?mt=12&amp;amp;uo=4&quot; rel=&quot;nofollow&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;http://linkmaker.itunes.apple.com/htmlResources/assets//images/web/linkmaker/badge_macappstore-sm.png&quot; alt=&quot;iTunesで見る&quot; class=&quot;sticky-itslinkbadge&quot; /&gt;&lt;/a&gt;&lt;br /&gt;&lt;span style=&quot;font-size:xx-small;&quot;&gt;posted with &lt;a href=&quot;http://sticky.linclip.com/linkmaker/&quot; target=&quot;_blank&quot;&gt;sticky&lt;/a&gt; on 2015.12.24&lt;/span&gt;&lt;/div&gt;&lt;br style=&quot;clear:left;&quot; /&gt;&lt;/div&gt;
</description>
        <pubDate>Thu, 17 Dec 2015 00:00:00 +0900</pubDate>
        <link>http://shoya.io/blog/texpad/</link>
        <guid isPermaLink="true">http://shoya.io/blog/texpad/</guid>
        
        <category>Note</category>
        
        
        <category>diary</category>
        
      </item>
    
      <item>
        <title>JINS MEMEのセンサデータをグラフ表示・csv出力するアプリを作りました</title>
        <description>&lt;p&gt;&lt;img src=&quot;https://dl.dropboxusercontent.com/u/12208857/img/github_memelogger_ios_dev_01.png&quot; class=&quot;image-on-frame-small&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://qiita.com/advent-calendar/2015/jinsmeme&quot;&gt;JINS MEME Advent Calendar 2015&lt;/a&gt; 3日目の記事です。昨日の記事は@hatoneさんによる &lt;cite&gt;&lt;a href=&quot;http://hatone.hateblo.jp/entry/2015/12/01/162235&quot;&gt;JINE MEME iOSアプリ開発入門 -公式サンプルアプリを動かす-&lt;/a&gt;&lt;/cite&gt;でした。サンプルアプリが動いたら、次はセンサから得られるデータについてもっと詳しく見てみたいはず！今日はセンサデータをグラフ表示したり保存する方法について紹介します。記事の前半は作ったものの紹介で後半は実装の工夫です。&lt;/p&gt;

&lt;h3 id=&quot;section&quot;&gt;背景&lt;/h3&gt;

&lt;p&gt;センサを使って何か面白いものを作るならデータの観察は欠かせません。そこで、観察に便利な&lt;strong&gt;波形のモニタリング&lt;/strong&gt;と&lt;strong&gt;ラベル付データの記録&lt;/strong&gt;機能を持ったアプリを作って&lt;a href=&quot;https://github.com/shoya140/MEMELogger-iOS-developers&quot;&gt;githubで公開しました&lt;/a&gt;。READMEに従ってAPP_IDとAPP_SECRETを書いたKey.hを作成してから実行してみてください。&lt;/p&gt;

&lt;h3 id=&quot;section-1&quot;&gt;機能&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;アプリ上でセンサデータをグラフ表示できる&lt;/li&gt;
  &lt;li&gt;オフライン解析のためにデータを記録できる&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;section-2&quot;&gt;実装&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;グラフ描画&lt;/strong&gt; 直近のデータを配列として保持しておき、UIBezierPathで連結することで描画しています。上限下限や色などはStoryboard上で変えられるようにIBInspectableを設定しました。&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-swift&quot; data-lang=&quot;swift&quot;&gt;&lt;span class=&quot;p&quot;&gt;@&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;IBDesignable&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nl&quot;&gt;GraphView&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;UIView&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;@&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;IBInspectable&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;var&lt;/span&gt; &lt;span class=&quot;nl&quot;&gt;maximumValue&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Double&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;1000.0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;kr&quot;&gt;didSet&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;nb&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;setNeedsDisplay&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;データの記録&lt;/strong&gt; 開発者がデータの読み書きに使えるDocumentDirectory以下にテキストファイルを作成し、&lt;code&gt;memeRealTimeModeDataReceived(data: MEMERealTimeData!)&lt;/code&gt;が呼ばれる度にそのデータを追記しています。また、iTunesやiFunBoxを使ってデータを取り出せるように&lt;code&gt;プロジェクト名-info.plist&lt;/code&gt;にKey:&lt;code&gt;Application supports iTunes file sharing&lt;/code&gt; Value:&lt;code&gt;YES&lt;/code&gt;をセットしました。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;まばたきのアニメーション&lt;/strong&gt; &lt;a href=&quot;http://www.paintcodeapp.com/&quot;&gt;PaintCode&lt;/a&gt;を使ってPathの位置を変数で変えられる目の画像を作成しました。PaintCodeから出力されたStyleKitをimportして、目の開閉や虹彩の位置とともにdraw~を呼び出して描画しています。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://dl.dropboxusercontent.com/u/12208857/img/github_memelogger_ios_dev_03.png&quot; class=&quot;image-on-frame-medium&quot; /&gt;&lt;/p&gt;

&lt;p&gt;その他の細かい実装についてはリポジトリをご参照ください。&lt;/p&gt;

&lt;h3 id=&quot;section-3&quot;&gt;まとめ&lt;/h3&gt;

&lt;p&gt;JINS MEMEのデータを観察する際に役立つアプリを作って公開しました。ご活用ください。&lt;a href=&quot;http://qiita.com/advent-calendar/2015/jinsmeme&quot;&gt;JINS MEME Advent Calendar2015&lt;/a&gt; 明日の担当は古川さんとのことでとても楽しみです！&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/shoya140/MEMELogger-iOS-developers&quot;&gt;https://github.com/shoya140/MEMELogger-iOS-developers&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
        <pubDate>Thu, 03 Dec 2015 00:00:00 +0900</pubDate>
        <link>http://shoya.io/blog/meme-logger/</link>
        <guid isPermaLink="true">http://shoya.io/blog/meme-logger/</guid>
        
        <category>ReleaseNote</category>
        
        <category>Programming</category>
        
        
        <category>tech</category>
        
      </item>
    
      <item>
        <title>深層学習の自己符号化器を4行で記述できるライブラリを作りました</title>
        <description>&lt;p&gt;深層学習(DeepLeanring)の事前学習や特徴抽出に使われる積層自己符号化器(stacked auto-encoder)を簡単に記述するためのライブラリ(Chainerインターフェイス)を作りました。名前はzChainerです。&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://pypi.python.org/pypi/zChainer/&quot;&gt;zChainer - scikit-learn like interface and stacked autoencoder for chainer&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://dl.dropboxusercontent.com/u/12208857/img/zchainer01.png&quot; class=&quot;image-on-frame-medium&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;section&quot;&gt;なぜ作ったか&lt;/h3&gt;

&lt;p&gt;ニューラルネットワークを簡単に実装することができるライブラリとしてChainerが多くの方に利用されていますが、ほぼ同じ記述を繰り返し書く必要があったり、学習器の定義・評価の記述が煩雑になりがちであるという課題があります。そこでインターフェイスとなるライブラリがあれば便利だと思って開発しました。scikt-learn likeに使うためにscikit-chainerとxchainerを参考にさせていただきました。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;cite&gt;&lt;a href=&quot;http://qiita.com/lucidfrontier45/items/0568d0d9e2c125e72734&quot;&gt;chainerをscikit-learn likeに使えるようにした&lt;/a&gt;&lt;/cite&gt;&lt;/li&gt;
  &lt;li&gt;&lt;cite&gt;&lt;a href=&quot;http://blog.recruit-tech.co.jp/2015/09/02/xchainer-released/&quot;&gt;NNライブラリChainerをScikit-learn likeにガンガン拡張する&lt;/a&gt;&lt;/cite&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;作ってみると積層自己符号化器の実装も共通なコードが多いことに気付いたので、本ライブラリは積層自己符号化器を管理するところまでインターフェイスに含めてみました。後述のサンプルコードのとおり、少ない行数(整形のための改行を除けばわずか4行)で記述することができます。&lt;/p&gt;

&lt;h3 id=&quot;section-1&quot;&gt;機能&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Chainerをscikit-learnの学習器として使用できる&lt;/li&gt;
  &lt;li&gt;少ない行数でニューラルネットワークを記述できる&lt;/li&gt;
  &lt;li&gt;少ない行数で積層自己符号化器を記述できる&lt;/li&gt;
  &lt;li&gt;出力先を指定するだけでログやシリアライズされたモデルを出力できる&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;section-2&quot;&gt;インストール方法&lt;/h3&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;pip install zChainer&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h3 id=&quot;section-3&quot;&gt;サンプルコード&lt;/h3&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;np&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;chainer.functions&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;F&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;chainer.links&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;L&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;chainer&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ChainList&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;optimizers&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;zChainer&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;NNAutoEncoder&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;utility&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;..&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;astype&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;float32&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# encoderの定義&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# 例)ノード数784-200-100のネットワーク&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# 学習後に出力層(MNISTの場合はノード数10)をadd_linkする&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;encoder&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ChainList&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;L&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Linear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;784&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;200&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;L&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Linear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;200&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# decoderの定義&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# encoderとノード数を反対にしたLinkをChainする&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;decoder&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ChainList&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;L&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Linear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;200&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;784&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;L&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Linear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;200&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# NNAutoEncoderインスタンスの作成&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;ae&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;NNAutoEncoder&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;encoder&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;decoder&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;optimizers&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Adam&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;epoch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;log_path&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;quot;./ae_&amp;quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;utility&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;now&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;quot;_log.csv&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;export_path&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;quot;./ae_&amp;quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;utility&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;now&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;quot;.model&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# 学習&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;ae&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;forward関数にはdropoutありのreluを登録していますが、好みのforward関数をセットすることもできます。詳しくは&lt;a href=&quot;https://github.com/shoya140/zChainer&quot;&gt;github&lt;/a&gt;のexampleをご確認ください。&lt;/p&gt;

&lt;h3 id=&quot;section-4&quot;&gt;実装&lt;/h3&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;class NNAutoEncoder &lt;span class=&quot;o&quot;&gt;()&lt;/span&gt;:
    def __init__&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;self, encoder, decoder, optimizer,
        &lt;span class=&quot;nv&quot;&gt;epoch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;20, &lt;span class=&quot;nv&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;100, &lt;span class=&quot;nv&quot;&gt;log_path&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;&amp;quot;&lt;/span&gt;, &lt;span class=&quot;nv&quot;&gt;export_path&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;&amp;quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;:
        self.encoder &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; encoder
        self.decoder &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; decoder
        self.optimizer &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; optimizer
        self.epoch &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; epoch
        self.batch_size &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; batch_size
        self.log_path &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; log_path
        self.export_path &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; export_path
        self.autoencoded &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; ChainList&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt;

    def fit&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;self, x_train&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;:
        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; layer in range&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;0, len&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;self.encoder&lt;span class=&quot;o&quot;&gt;))&lt;/span&gt;:
            &lt;span class=&quot;c&quot;&gt;# Creating model&lt;/span&gt;
            self.model &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; ChainList&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;self.encoder&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;layer&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt;.copy&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt;, self.decoder&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;layer&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt;.copy&lt;span class=&quot;o&quot;&gt;())&lt;/span&gt;
            NNManager.forward &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; self.forward
            &lt;span class=&quot;nv&quot;&gt;nn&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; NNManager&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;self.model, self.optimizer, F.mean_squared_error,
                self.epoch, self.batch_size, self.log_path&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;

            &lt;span class=&quot;c&quot;&gt;# Training&lt;/span&gt;
            &lt;span class=&quot;nv&quot;&gt;x_data&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; self.encode&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;x_train, layer&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;.data
            nn.fit&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;x_data, x_data&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
            self.autoencoded.add_link&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;nn.model&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;0&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt;.copy&lt;span class=&quot;o&quot;&gt;())&lt;/span&gt;

        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; self.export_path !&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;&amp;quot;&lt;/span&gt;:
            pickle.dump&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;self.autoencoded, open&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;self.export_path, &lt;span class=&quot;s1&quot;&gt;&amp;#39;wb&amp;#39;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;, -1&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; self

    def predict&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;self, x_test&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;:
        raise Exception&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;Prediction for AutoEncoder is not implemented.&amp;quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;

    def encode&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;self, x, n&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;:
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;n&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; 0:
            &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; Variable&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;x&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt;:
            &lt;span class=&quot;nv&quot;&gt;h&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; self.encode&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;x, n-1&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; F.relu&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;self.autoencoded&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;n-1&lt;span class=&quot;o&quot;&gt;](&lt;/span&gt;h&lt;span class=&quot;o&quot;&gt;))&lt;/span&gt;

    def forward&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;self, x&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;:
        &lt;span class=&quot;nv&quot;&gt;h&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; F.dropout&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;F.relu&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;self.model&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;0&lt;span class=&quot;o&quot;&gt;](&lt;/span&gt;x&lt;span class=&quot;o&quot;&gt;)))&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; F.dropout&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;F.relu&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;self.model&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;1&lt;span class=&quot;o&quot;&gt;](&lt;/span&gt;h&lt;span class=&quot;o&quot;&gt;)))&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Chainer1.5のLink and Chainを使用しています。ネットワークの構造をChainではなくChainListとして管理することで各層に添字でアクセスできるようにして、学習が済んだものをself.autoencodedにコピーしています。学習済みモデル最先端の層からの出力はencoded関数を再帰的に呼ぶことで得ています。(層が深くなるにつれて遅くなるかも？時間ができれば改良したい)&lt;/p&gt;

&lt;h3 id=&quot;section-5&quot;&gt;まとめ&lt;/h3&gt;

&lt;p&gt;積層自己符号化器を含めたChainerのインターフェイスとなるライブラリを作成しました。時間の都合で十分検証ができていないので、不具合などあるかもしれません。おかしいところがあれば連絡いただけると嬉しいです。バージョン1.0になるまで使用は自己責任でお願いします。&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/shoya140/zChainer&quot;&gt;https://github.com/shoya140/zChainer&lt;/a&gt;&lt;/p&gt;
</description>
        <pubDate>Wed, 02 Dec 2015 00:00:00 +0900</pubDate>
        <link>http://shoya.io/blog/zchainer/</link>
        <guid isPermaLink="true">http://shoya.io/blog/zchainer/</guid>
        
        <category>ReleaseNote</category>
        
        <category>Programming</category>
        
        
        <category>tech</category>
        
      </item>
    
      <item>
        <title>大体いい感じの研究発表ができるKeynoteテンプレート「Zebra」を作った</title>
        <description>&lt;script async=&quot;&quot; class=&quot;speakerdeck-embed&quot; data-id=&quot;33dbc4b1166e45cca57400eeeaf0db4f&quot; data-ratio=&quot;1.33333333333333&quot; src=&quot;//speakerdeck.com/assets/embed.js&quot;&gt;&lt;/script&gt;

&lt;h3 id=&quot;section&quot;&gt;なぜ作ったか&lt;/h3&gt;

&lt;p&gt;僕の観測範囲では、研究発表のスライドというのは装飾が最小限で、白地に黒文字が読みやすくて良いとされています。その制約の中で見栄えの良いスライドを作るのはなかなか難しいので、大体いい感じになるKeynoteテンプレートを作りました。名前はZebraです。こちらからダウンロードすることができます。&lt;cite&gt;&lt;a href=&quot;https://github.com/shoya140/zebra&quot;&gt;Zebra — Keynote template for research presentations&lt;/a&gt;&lt;/cite&gt;&lt;/p&gt;

&lt;p&gt;テンプレート作成/公開にあたって参考にさせていただいたのは&lt;a href=&quot;http://www.sanographix.net/&quot;&gt;佐野章核&lt;/a&gt;さんの「Azusa」「Azusa Colors」で、勉強会やLTのスライドではいつもお世話になっています。
&lt;cite&gt;&lt;a href=&quot;http://memo.sanographix.net/post/82160791768&quot;&gt;大体いい感じになるKeynoteテンプレート「Azusa」作った - MEMOGRAPHIX&lt;/a&gt;&lt;/cite&gt; ただ研究発表のような堅い場所で使うにはややポップすぎる感じがするのと、透過でない図やグラフを貼る機会が多くて真っ白な背景が使いたいので、今回はそれに適したテンプレートを作成することにしました。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://dl.dropboxusercontent.com/u/12208857/img/zebra1.jpg&quot; class=&quot;image-on-frame-medium&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;section-1&quot;&gt;機能&lt;/h3&gt;

&lt;p&gt;title, outline, blank, mainの4種類のフォーマットと2種類のカラースキームで構成されています。mainのスライド上部には目立つが主張し過ぎない見出しを置いています。見出しの色は変えられるので好きな色を使ってください。スライドのメインカラーとリンクさせると綺麗です。スライドに使用する色は極力3色(背景・ベースカラー・メインカラー)に押さえて、課題-解決策の対比や強く伝えたいことにアクセントカラーを使うのが良いと思います。フォントはMac標準搭載のもののなかからAvenir Nextを選択しました。これも好みで選んでください。&lt;/p&gt;

&lt;h3 id=&quot;section-2&quot;&gt;まとめ&lt;/h3&gt;

&lt;p&gt;フォーマルだけど少しお洒落、大体いい感じの研究発表ができるKeynoteテンプレートを作って公開しました。ご活用ください。不具合などありましたらissue立てるか直接連絡いただけると嬉しいです。Zebra使って最高の卒論/修論発表にしようぜ！&lt;/p&gt;

&lt;p&gt;&lt;cite&gt;&lt;a href=&quot;https://github.com/shoya140/zebra&quot;&gt;Zebra — Keynote template for research presentations&lt;/a&gt;&lt;/cite&gt;&lt;/p&gt;
</description>
        <pubDate>Fri, 13 Nov 2015 00:00:00 +0900</pubDate>
        <link>http://shoya.io/blog/zebra/</link>
        <guid isPermaLink="true">http://shoya.io/blog/zebra/</guid>
        
        <category>ReleaseNote</category>
        
        <category>Design</category>
        
        
        <category>diary</category>
        
      </item>
    
      <item>
        <title>Google Glassを修理する</title>
        <description>&lt;h3 id=&quot;section&quot;&gt;背景&lt;/h3&gt;

&lt;p&gt;Google Glassには本体から送られる光を目に届けるためのプリズムが付いているのだけれど、高温多湿な場所で使っているとプリズムの先端に貼られているミラーフィルムが剥がれて画面が見えなくなってしまう。調べてみると割とよくある事例らしく、Googleに問い合わせた人もいる模様。(&lt;cite&gt;&lt;a href=&quot;http://glassalmanac.com/google-glass-mortal-enemy-high-temps-humidity/656/&quot;&gt;High Temps are Damaging Google Glass Beyond Repair&lt;/a&gt;&lt;/cite&gt;, &lt;cite&gt;&lt;a href=&quot;https://www.reddit.com/r/googleglass/comments/292rzy/whats_happing_to_the_film_on_my_google_glass/&quot;&gt;Whats Happing to the film on my Google Glass?&lt;/a&gt;&lt;/cite&gt;) しかし手元のGoogle GlassはAmazon経由で購入ており問い合わせが難しいので、自分で修理することにした。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://dl.dropboxusercontent.com/u/12208857/img/reparing01.jpg&quot; class=&quot;image-on-frame-medium&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;section-1&quot;&gt;解決策&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;※修理は自己責任でお願いします。失敗したり保証を失っても一切の責任を負いかねます。&lt;/strong&gt;&lt;br /&gt;
用意するもの: 金属光沢シート・はさみ(カッター)・ピンセット&lt;/p&gt;

&lt;div class=&quot;babylink-box&quot; style=&quot;overflow: hidden; font-size: small; zoom: 1; margin: 15px 0; text-align: left;&quot;&gt;&lt;div class=&quot;babylink-image&quot; style=&quot;float: left; margin: 0px 15px 10px 0px; width: 75px; height: 75px; text-align: center;&quot;&gt;&lt;a href=&quot;http://www.amazon.co.jp/exec/obidos/ASIN/B001GQ2WP8/mrk1869-22/&quot; rel=&quot;nofollow&quot; target=&quot;_blank&quot;&gt;&lt;img style=&quot;border-top: medium none; border-right: medium none; border-bottom: medium none; border-left: medium none;&quot; src=&quot;http://ecx.images-amazon.com/images/I/41o25COrUcL._SL75_.jpg&quot; width=&quot;36&quot; height=&quot;75&quot; /&gt;&lt;/a&gt;&lt;/div&gt;&lt;div class=&quot;babylink-info&quot; style=&quot;overflow: hidden; zoom: 1; line-height: 120%;&quot;&gt;&lt;div class=&quot;babylink-title&quot; style=&quot;margin-bottom: 2px; line-height: 120%;&quot;&gt;&lt;a href=&quot;http://www.amazon.co.jp/exec/obidos/ASIN/B001GQ2WP8/mrk1869-22/&quot; rel=&quot;nofollow&quot; target=&quot;_blank&quot;&gt;トライツール TF01 ミラー フィニッシュ&lt;/a&gt;&lt;/div&gt;&lt;div class=&quot;babylink-manufacturer&quot; style=&quot;margin-bottom: 5px;&quot;&gt;ハセガワ&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;booklink-footer&quot; style=&quot;clear: left&quot;&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ol&gt;
  &lt;li&gt;表面に残ったフィルムを剥がす。(セロハンテープで上から押さえると綺麗に剥がれる。)&lt;/li&gt;
  &lt;li&gt;金属光沢シートをプリズムの大きさに合わせて切り、ピンセットで乗せる。&lt;/li&gt;
  &lt;li&gt;吸着するまで3-4分待つ。今までどおり画面が見えるようになる。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;img src=&quot;https://dl.dropboxusercontent.com/u/12208857/img/reparing02.jpg&quot; class=&quot;image-on-frame-medium&quot; /&gt;&lt;/p&gt;

&lt;p&gt;金属光沢シートを乗せた後はすぐに指で押したりせず自然と吸着するのを待ちましょう。気泡が入ると像がぼやけます。5,6回繰り返すうちに上手に貼ることができました。&lt;/p&gt;

&lt;h3 id=&quot;section-2&quot;&gt;おまけ(うまくいかなかった例)&lt;/h3&gt;

&lt;p&gt;いろいろ材料を探して試してみたところ、上記の金属光沢シートが一番良さそうでした。最初に試したアルミテープは光沢が十分ではなくて鏡として使えず、像を結ぶことができませんでした。金属光沢シートと一緒に両面テープも買ったのですが、シート自体に吸着力があったので必要ありませんでした。&lt;/p&gt;

&lt;div class=&quot;babylink-box&quot; style=&quot;overflow: hidden; font-size: small; zoom: 1; margin: 15px 0; text-align: left;&quot;&gt;&lt;div class=&quot;babylink-image&quot; style=&quot;float: left; margin: 0px 15px 10px 0px; width: 75px; height: 75px; text-align: center;&quot;&gt;&lt;a href=&quot;http://www.amazon.co.jp/exec/obidos/ASIN/B00I4NQNJC/mrk1869-22/&quot; rel=&quot;nofollow&quot; target=&quot;_blank&quot;&gt;&lt;img style=&quot;border-top: medium none; border-right: medium none; border-bottom: medium none; border-left: medium none;&quot; src=&quot;http://ecx.images-amazon.com/images/I/41A1pi3DmXL._SL75_.jpg&quot; width=&quot;75&quot; height=&quot;74&quot; /&gt;&lt;/a&gt;&lt;/div&gt;&lt;div class=&quot;babylink-info&quot; style=&quot;overflow: hidden; zoom: 1; line-height: 120%;&quot;&gt;&lt;div class=&quot;babylink-title&quot; style=&quot;margin-bottom: 2px; line-height: 120%;&quot;&gt;&lt;a href=&quot;http://www.amazon.co.jp/exec/obidos/ASIN/B00I4NQNJC/mrk1869-22/&quot; rel=&quot;nofollow&quot; target=&quot;_blank&quot;&gt;エル日昌 アルミテープ(ツヤアリ)50mmx10m LM1025010&lt;/a&gt;&lt;/div&gt;&lt;div class=&quot;babylink-manufacturer&quot; style=&quot;margin-bottom: 5px;&quot;&gt;エル日昌&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;booklink-footer&quot; style=&quot;clear: left&quot;&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;babylink-box&quot; style=&quot;overflow: hidden; font-size: small; zoom: 1; margin: 15px 0; text-align: left;&quot;&gt;&lt;div class=&quot;babylink-image&quot; style=&quot;float: left; margin: 0px 15px 10px 0px; width: 75px; height: 75px; text-align: center;&quot;&gt;&lt;a href=&quot;http://www.amazon.co.jp/exec/obidos/ASIN/B002YMOUDA/mrk1869-22/&quot; rel=&quot;nofollow&quot; target=&quot;_blank&quot;&gt;&lt;img style=&quot;border-top: medium none; border-right: medium none; border-bottom: medium none; border-left: medium none;&quot; src=&quot;http://ecx.images-amazon.com/images/I/51DUq6IdhoL._SL75_.jpg&quot; width=&quot;75&quot; height=&quot;75&quot; /&gt;&lt;/a&gt;&lt;/div&gt;&lt;div class=&quot;babylink-info&quot; style=&quot;overflow: hidden; zoom: 1; line-height: 120%;&quot;&gt;&lt;div class=&quot;babylink-title&quot; style=&quot;margin-bottom: 2px; line-height: 120%;&quot;&gt;&lt;a href=&quot;http://www.amazon.co.jp/exec/obidos/ASIN/B002YMOUDA/mrk1869-22/&quot; rel=&quot;nofollow&quot; target=&quot;_blank&quot;&gt;3M スコッチ 超強力両面テープ 透明素材用 12mm×4m STD-12&lt;/a&gt;&lt;/div&gt;&lt;div class=&quot;babylink-manufacturer&quot; style=&quot;margin-bottom: 5px;&quot;&gt;3M (スリーエム)&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;booklink-footer&quot; style=&quot;clear: left&quot;&gt;&lt;/div&gt;&lt;/div&gt;
</description>
        <pubDate>Tue, 03 Nov 2015 00:00:00 +0900</pubDate>
        <link>http://shoya.io/blog/repairing-google-glass/</link>
        <guid isPermaLink="true">http://shoya.io/blog/repairing-google-glass/</guid>
        
        <category>Note</category>
        
        
        <category>diary</category>
        
      </item>
    
      <item>
        <title>学長顕彰2</title>
        <description>&lt;p&gt;大学在学中2度目の学長顕彰を戴きました。&lt;a href=&quot;/blog/honor/&quot;&gt;前回(3年前)受賞した時&lt;/a&gt;に「次は研究で成果をあげられるよう頑張ります」と言っていたので有言実行ということで:)&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://dl.dropboxusercontent.com/u/12208857/img/honor2.jpg&quot; class=&quot;image-on-frame-medium&quot; /&gt;&lt;/p&gt;
</description>
        <pubDate>Mon, 02 Nov 2015 00:00:00 +0900</pubDate>
        <link>http://shoya.io/blog/honor2/</link>
        <guid isPermaLink="true">http://shoya.io/blog/honor2/</guid>
        
        <category>Note</category>
        
        
        <category>diary</category>
        
      </item>
    
      <item>
        <title>ドキュメント考2015</title>
        <description>&lt;p&gt;PCでとるメモの保存先について環境や目的の変化に合わせてこれまでいろんなツールを試してきたので、それらを踏まえて現状こんな感じというのを共有します。&lt;/p&gt;

&lt;h3 id=&quot;section&quot;&gt;ドキュメント遍歴&lt;/h3&gt;

&lt;p&gt;大学1-2年生(2010-2011年)の頃は今みたいに外で常時ネットに接続する環境がなかった。テキストファイルをPCに保存して、外出先で必要そうなものをあらかじめiPod touchに入れておいて&lt;a href=&quot;http://www.goodreader.com/&quot;&gt;GoodReader&lt;/a&gt;とかで見てた。PC上のファイルはディレクトリ分けによって管理していたので探すのが面倒だった。途中から&lt;a href=&quot;https://www.evernote.com/&quot;&gt;Evernote&lt;/a&gt;を使い始めて、全てひとつの場所に放り込んで検索する便利さを知った。iPod touchでも一部のノートをオフラインで開けるようにしてした。&lt;/p&gt;

&lt;p&gt;大学3年生(2012年)の頃にiPhoneを手にしてからはEvernoteを利用する機会が増えた。検索が楽になって外でも開けてとても便利。しかし&lt;a href=&quot;http://markovlabo.net/?p=1165&quot;&gt;ノート数が増えるに従ってPC/iPhoneアプリの挙動が不安定になった&lt;/a&gt;。ブラウザからしかアクセスしなくなり、ライフログやWebクリップの保管場所にしか使われなくなった。&lt;/p&gt;

&lt;p&gt;大学4年生(2013年)の頃から代わりに使い始めたのが&lt;a href=&quot;http://dayoneapp.com/&quot;&gt;DayOne&lt;/a&gt;というアプリで、Markdownでメモが取れる上に起動や同期が早くUIも綺麗。エディタとしては申し分ない環境だった。しかし少しだけ残念なところが2つある。それは好きな場所に画像を貼れないこと(外部においてマークダウンで読み込むことはできるが)と、EvernoteやDropbox, GoogleDriveのようなURLでドキュメントを限定公開する機能がないことだ。ドキュメントを他者と共有する機会が増えてきて、なんとかしたいと思っていた。&lt;/p&gt;

&lt;p&gt;共同作業するときはだいたい&lt;a href=&quot;https://www.google.com/intl/ja/drive/&quot;&gt;GoogleDrive&lt;/a&gt;を使っているけど、オフラインだと使えないしブラウザ上で作業するのは不便なので個人の作業場所・ドキュメント保管場所には向いていない。また、用紙のサイズとかレイアウトとかいらないしMarkdownで書きたいという思いがあって自作のWikiを運用していたこともあったけど、やはりブラウザ上でしか編集できないのは大きな欠点だった。&lt;/p&gt;

&lt;h3 id=&quot;evernote-alternote&quot;&gt;Evernote + Alternote&lt;/h3&gt;

&lt;p&gt;では今はどうしているかというと、Evernoteに戻ってきて落ち着いた。使い方は昔とは変わり、自動的になんでも保存するのではなく、自分で書いた文章など必要なものだけを残している。新しいアカウントを作ってノートの数を絞ると同期も問題なく行えるようになった。久々に起動したEvernoteのクライアントアプリはいろいろと進化していて、特にプレゼンテーションモードは重宝している。未だエディタとしては使いづらいので、Macから文章を書くときは&lt;a href=&quot;http://alternoteapp.com/&quot;&gt;Alternote&lt;/a&gt;というアプリを使って保存している。Alternoteは主要な機能にショートカットキーが割り当てられていて書くことに専念できるEveroteエディタ。Markdownをリッチテキスト変換してくれる機能もあるけれど、テキストを他の媒体に貼り付けるときに記号が消えては困るのでオプションを切ってMarkdownには脳内で変換している。&lt;/p&gt;

&lt;h3 id=&quot;section-1&quot;&gt;まとめ&lt;/h3&gt;

&lt;p&gt;自分がドキュメントツールに求める機能は以下のとおり(優先度順)。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;複数端末で同期できる&lt;/li&gt;
  &lt;li&gt;エディタとして使いやすい(起動が早く気持ちよく書ける)&lt;/li&gt;
  &lt;li&gt;ディレクトリの概念がない(検索とタグで探す)&lt;/li&gt;
  &lt;li&gt;URL限定公開ができる&lt;/li&gt;
  &lt;li&gt;共同編集ができる&lt;/li&gt;
  &lt;li&gt;画像を貼り付けることができる&lt;/li&gt;
  &lt;li&gt;Markdownで書ける&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;現状では軽量化したEvernoteとAlternoteを使うのが良い感じです。&lt;/p&gt;
</description>
        <pubDate>Tue, 06 Oct 2015 00:00:00 +0900</pubDate>
        <link>http://shoya.io/blog/document_tools/</link>
        <guid isPermaLink="true">http://shoya.io/blog/document_tools/</guid>
        
        <category>Note</category>
        
        
        <category>diary</category>
        
      </item>
    
  </channel>
</rss>
